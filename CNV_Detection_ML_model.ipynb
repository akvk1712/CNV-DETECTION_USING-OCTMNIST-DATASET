{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Load the ZNP file\n",
        "data = np.load(\"/content/octmnist.npz\")\n",
        "\n",
        "# Access images and labels\n",
        "images = data[\"images\"]\n",
        "labels = data[\"labels\"]\n",
        "\n",
        "# View the first image\n",
        "image = np.squeeze(images[0]) * 255.0\n",
        "image = Image.fromarray(image.astype(np.uint8)).convert(\"L\")\n",
        "image.show()\n",
        "\n",
        "# Print the corresponding label\n",
        "print(f\"Label: {labels[0]}\")"
      ],
      "metadata": {
        "id": "dafuzOW5BorY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset code\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from medmnist.info import INFO, HOMEPAGE, DEFAULT_ROOT\n",
        "\n",
        "\n",
        "class MedMNIST(Dataset):\n",
        "\n",
        "    flag = ...\n",
        "\n",
        "    def __init__(self,\n",
        "                 split,\n",
        "                 transform=None,\n",
        "                 target_transform=None,\n",
        "                 download=False,\n",
        "                 as_rgb=False,\n",
        "                 root=DEFAULT_ROOT):\n",
        "        ''' dataset\n",
        "        :param split: 'train', 'val' or 'test', select subset\n",
        "        :param transform: data transformation\n",
        "        :param target_transform: target transformation\n",
        "\n",
        "        '''\n",
        "\n",
        "        self.info = INFO[self.flag]\n",
        "\n",
        "        if root is not None and os.path.exists(root):\n",
        "            self.root = root\n",
        "        else:\n",
        "            raise RuntimeError(\"Failed to setup the default `root` directory. \" +\n",
        "                               \"Please specify and create the `root` directory manually.\")\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not os.path.exists(\n",
        "                os.path.join(self.root, \"{}.npz\".format(self.flag))):\n",
        "            raise RuntimeError('Dataset not found. ' +\n",
        "                               ' You can set `download=True` to download it')\n",
        "\n",
        "        npz_file = np.load(os.path.join(self.root, \"{}.npz\".format(self.flag)))\n",
        "\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.as_rgb = as_rgb\n",
        "\n",
        "        if self.split == 'train':\n",
        "            self.imgs = npz_file['train_images']\n",
        "            self.labels = npz_file['train_labels']\n",
        "        elif self.split == 'val':\n",
        "            self.imgs = npz_file['val_images']\n",
        "            self.labels = npz_file['val_labels']\n",
        "        elif self.split == 'test':\n",
        "            self.imgs = npz_file['test_images']\n",
        "            self.labels = npz_file['test_labels']\n",
        "        else:\n",
        "            raise ValueError\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.imgs.shape[0]\n",
        "\n",
        "    def __repr__(self):\n",
        "        '''Adapted from torchvision.ss'''\n",
        "        _repr_indent = 4\n",
        "        head = f\"Dataset {self.__class__.__name__} ({self.flag})\"\n",
        "        body = [f\"Number of datapoints: {self.__len__()}\"]\n",
        "        body.append(f\"Root location: {self.root}\")\n",
        "        body.append(f\"Split: {self.split}\")\n",
        "        body.append(f\"Task: {self.info['task']}\")\n",
        "        body.append(f\"Number of channels: {self.info['n_channels']}\")\n",
        "        body.append(f\"Meaning of labels: {self.info['label']}\")\n",
        "        body.append(f\"Number of samples: {self.info['n_samples']}\")\n",
        "        body.append(f\"Description: {self.info['description']}\")\n",
        "        body.append(f\"License: {self.info['license']}\")\n",
        "\n",
        "        lines = [head] + [\" \" * _repr_indent + line for line in body]\n",
        "        return '\\n'.join(lines)\n",
        "\n",
        "    def download(self):\n",
        "        try:\n",
        "            from torchvision.datasets.utils import download_url\n",
        "            download_url(url=self.info[\"url\"],\n",
        "                         root=self.root,\n",
        "                         filename=\"{}.npz\".format(self.flag),\n",
        "                         md5=self.info[\"MD5\"])\n",
        "        except:\n",
        "            raise RuntimeError('Something went wrong when downloading! ' +\n",
        "                               'Go to the homepage to download manually. ' +\n",
        "                               HOMEPAGE)\n",
        "\n",
        "\n",
        "class MedMNIST2D(MedMNIST):\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        return: (without transform/target_transofrm)\n",
        "            img: PIL.Image\n",
        "            target: np.array of `L` (L=1 for single-label)\n",
        "        '''\n",
        "        img, target = self.imgs[index], self.labels[index].astype(int)\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.as_rgb:\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def save(self, folder, postfix=\"png\", write_csv=True):\n",
        "\n",
        "        from medmnist.utils import save2d\n",
        "\n",
        "        save2d(imgs=self.imgs,\n",
        "               labels=self.labels,\n",
        "               img_folder=os.path.join(folder, self.flag),\n",
        "               split=self.split,\n",
        "               postfix=postfix,\n",
        "               csv_path=os.path.join(folder, f\"{self.flag}.csv\") if write_csv else None)\n",
        "\n",
        "    def montage(self, length=20, replace=False, save_folder=None):\n",
        "        from medmnist.utils import montage2d\n",
        "\n",
        "        n_sel = length * length\n",
        "        sel = np.random.choice(self.__len__(), size=n_sel, replace=replace)\n",
        "\n",
        "        montage_img = montage2d(imgs=self.imgs,\n",
        "                                n_channels=self.info['n_channels'],\n",
        "                                sel=sel)\n",
        "\n",
        "        if save_folder is not None:\n",
        "            if not os.path.exists(save_folder):\n",
        "                os.makedirs(save_folder)\n",
        "            montage_img.save(os.path.join(save_folder,\n",
        "                                          f\"{self.flag}_{self.split}_montage.jpg\"))\n",
        "\n",
        "        return montage_img\n",
        "\n",
        "\n",
        "class MedMNIST3D(MedMNIST):\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        return: (without transform/target_transofrm)\n",
        "            img: an array of 1x28x28x28 or 3x28x28x28 (if `as_RGB=True`), in [0,1]\n",
        "            target: np.array of `L` (L=1 for single-label)\n",
        "        '''\n",
        "        img, target = self.imgs[index], self.labels[index].astype(int)\n",
        "\n",
        "        img = np.stack([img/255.]*(3 if self.as_rgb else 1), axis=0)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def save(self, folder, postfix=\"gif\", write_csv=True):\n",
        "        from medmnist.utils import save3d\n",
        "\n",
        "        assert postfix == \"gif\"\n",
        "\n",
        "        save3d(imgs=self.imgs,\n",
        "               labels=self.labels,\n",
        "               img_folder=os.path.join(folder, self.flag),\n",
        "               split=self.split,\n",
        "               postfix=postfix,\n",
        "               csv_path=os.path.join(folder, f\"{self.flag}.csv\") if write_csv else None)\n",
        "\n",
        "    def montage(self, length=20, replace=False, save_folder=None):\n",
        "        assert self.info['n_channels'] == 1\n",
        "\n",
        "        from medmnist.utils import montage3d, save_frames_as_gif\n",
        "        n_sel = length * length\n",
        "        sel = np.random.choice(self.__len__(), size=n_sel, replace=replace)\n",
        "\n",
        "        montage_frames = montage3d(imgs=self.imgs,\n",
        "                                   n_channels=self.info['n_channels'],\n",
        "                                   sel=sel)\n",
        "\n",
        "        if save_folder is not None:\n",
        "            if not os.path.exists(save_folder):\n",
        "                os.makedirs(save_folder)\n",
        "\n",
        "            save_frames_as_gif(montage_frames,\n",
        "                               os.path.join(save_folder,\n",
        "                                            f\"{self.flag}_{self.split}_montage.gif\"))\n",
        "\n",
        "        return montage_frames\n",
        "\n",
        "\n",
        "class PathMNIST(MedMNIST2D):\n",
        "    flag = \"pathmnist\"\n",
        "\n",
        "\n",
        "class OCTMNIST(MedMNIST2D):\n",
        "    flag = \"octmnist\"\n",
        "\n",
        "\n",
        "class PneumoniaMNIST(MedMNIST2D):\n",
        "    flag = \"pneumoniamnist\"\n",
        "\n",
        "\n",
        "class ChestMNIST(MedMNIST2D):\n",
        "    flag = \"chestmnist\"\n",
        "\n",
        "\n",
        "class DermaMNIST(MedMNIST2D):\n",
        "    flag = \"dermamnist\"\n",
        "\n",
        "\n",
        "class RetinaMNIST(MedMNIST2D):\n",
        "    flag = \"retinamnist\"\n",
        "\n",
        "\n",
        "class BreastMNIST(MedMNIST2D):\n",
        "    flag = \"breastmnist\"\n",
        "\n",
        "\n",
        "class BloodMNIST(MedMNIST2D):\n",
        "    flag = \"bloodmnist\"\n",
        "\n",
        "\n",
        "class TissueMNIST(MedMNIST2D):\n",
        "    flag = \"tissuemnist\"\n",
        "\n",
        "\n",
        "class OrganAMNIST(MedMNIST2D):\n",
        "    flag = \"organamnist\"\n",
        "\n",
        "\n",
        "class OrganCMNIST(MedMNIST2D):\n",
        "    flag = \"organcmnist\"\n",
        "\n",
        "\n",
        "class OrganSMNIST(MedMNIST2D):\n",
        "    flag = \"organsmnist\"\n",
        "\n",
        "\n",
        "class OrganMNIST3D(MedMNIST3D):\n",
        "    flag = \"organmnist3d\"\n",
        "\n",
        "\n",
        "class NoduleMNIST3D(MedMNIST3D):\n",
        "    flag = \"nodulemnist3d\"\n",
        "\n",
        "\n",
        "class AdrenalMNIST3D(MedMNIST3D):\n",
        "    flag = \"adrenalmnist3d\"\n",
        "\n",
        "\n",
        "class FractureMNIST3D(MedMNIST3D):\n",
        "    flag = \"fracturemnist3d\"\n",
        "\n",
        "\n",
        "class VesselMNIST3D(MedMNIST3D):\n",
        "    flag = \"vesselmnist3d\"\n",
        "\n",
        "\n",
        "class SynapseMNIST3D(MedMNIST3D):\n",
        "    flag = \"synapsemnist3d\"\n",
        "\n",
        "\n",
        "# backward-compatible\n",
        "OrganMNISTAxial = OrganAMNIST\n",
        "OrganMNISTCoronal = OrganCMNIST\n",
        "OrganMNISTSagittal = OrganSMNIST"
      ],
      "metadata": {
        "id": "0vUIhHpGstkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lime\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from scipy.interpolate import interp2d\n",
        "\n",
        "# Define custom CNN loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    confidence_loss = tf.keras.losses.MeanSquaredError(reduction=\"auto\")(y_true[0], y_pred[0])\n",
        "    localization_loss = tf.keras.losses.MeanSquaredError(reduction=\"auto\")(y_true[1], y_pred[1])\n",
        "    class_loss = tf.keras.losses.BinaryCrossentropy(reduction=\"auto\")(y_true[2], y_pred[2])\n",
        "\n",
        "    combined_loss = 0.5 * confidence_loss + 0.3 * localization_loss + 0.2 * class_loss\n",
        "\n",
        "    return combined_loss\n",
        "\n",
        "class CNN(models.Model):\n",
        "    def __init__(self, num_classes, input_shape=(28, 28, 1)):\n",
        "        super(CNN, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "        self.vgg16 = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "        self.resnet50 = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "\n",
        "        for layer in self.vgg16.layers:\n",
        "            layer.trainable = False\n",
        "        for layer in self.resnet50.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        inputs = layers.Input(shape=input_shape)\n",
        "        self.vgg_features = self.vgg16(inputs)\n",
        "        self.resnet_features = self.resnet50(inputs)\n",
        "\n",
        "        merged_features = layers.concatenate([self.vgg_features, self.resnet_features])\n",
        "\n",
        "        self.conv1 = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(merged_features)\n",
        "        self.maxpool1 = layers.MaxPooling2D(pool_size=(2, 2))(self.conv1)\n",
        "        self.conv2 = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(self.maxpool1)\n",
        "        self.maxpool2 = layers.MaxPooling2D(pool_size=(2, 2))(self.conv2)\n",
        "        # ... (additional layers)\n",
        "\n",
        "        self.flatten = layers.Flatten()(self.maxpool2)\n",
        "        self.fc1 = layers.Dense(128, activation=\"relu\")(self.flatten)\n",
        "        self.fc2 = layers.Dense(64, activation=\"relu\")(self.fc1)\n",
        "        # ... (additional layers)\n",
        "\n",
        "        self.fc3 = layers.Dense(num_classes, activation=\"softmax\")(self.fc2)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.fc3(self.vgg16(inputs) + self.resnet50(inputs))\n",
        "\n",
        "def resize(image, desired_size=(256, 256)):\n",
        "    scale_y = desired_size[0] / image.shape[0]\n",
        "    scale_x = desired_size[1] / image.shape[1]\n",
        "\n",
        "    rows = np.arange(0, image.shape[0])\n",
        "    cols = np.arange(0, image.shape[1])\n",
        "\n",
        "    rows_resized = np.arange(0, desired_size[0], scale_y)\n",
        "    cols_resized = np.arange(0, desired_size[1], scale_x)\n",
        "\n",
        "    interpolator_r = interp2d(cols, rows, image[:, :, 0], kind='cubic', bounds_error=False, fill_value=0)\n",
        "    interpolator_g = interp2d(cols, rows, image[:, :, 1], kind='cubic', bounds_error=False, fill_value=0)\n",
        "    interpolator_b = interp2d(cols, rows, image[:, :, 2], kind='cubic', bounds_error=False, fill_value=0)\n",
        "\n",
        "    resized_image_r = interpolator_r(cols_resized, rows_resized)\n",
        "    resized_image_g = interpolator_g(cols_resized, rows_resized)\n",
        "    resized_image_b = interpolator_b(cols_resized, rows_resized)\n",
        "\n",
        "    resized_image = np.stack([resized_image_r, resized_image_g, resized_image_b], axis=-1)\n",
        "\n",
        "    return resized_image\n",
        "\n",
        "def preprocess_cnv(image):\n",
        "    original_shape = image.shape\n",
        "    filtered_image = image + np.random.normal(size=original_shape, scale=0.05)\n",
        "    enhanced_image = filtered_image + np.mean(filtered_image) - np.mean(image)\n",
        "    roi_size = int(min(original_shape[0], original_shape[1]) / 2)\n",
        "    roi_x = int((original_shape[0] - roi_size) / 2)\n",
        "    roi_y = int((original_shape[1] - roi_size) / 2)\n",
        "    roi_image = enhanced_image[roi_x:roi_x + roi_size, roi_y:roi_y + roi_size]\n",
        "    return roi_image\n",
        "\n",
        "def preprocess_normal(image, dtype=np.float32):\n",
        "    image = image.astype(dtype)\n",
        "    image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "    return image\n",
        "\n",
        "def load_data(path=\"/content/octmnist.npz\"):\n",
        "    with np.load(path) as data:\n",
        "        images = data[\"images\"]\n",
        "        labels = data[\"labels\"]\n",
        "\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "X, y = load_data()\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=5,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        ")\n",
        "\n",
        "model = CNN(num_classes=2)\n",
        "model.compile(loss=custom_loss, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5)\n",
        "\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "          epochs=20,\n",
        "          validation_data=(X_val, y_val),\n",
        "          callbacks=[early_stopping])\n",
        "\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f\"\\nModel Evaluation:\\nLoss: {loss:.4f}\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred = model.predict(X_val)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Convert one-hot encoded labels to class labels\n",
        "y_val_class = np.argmax(y_val, axis=1)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_val_class, y_pred_class)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_val_class, y_pred_class)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_val_class, y_pred_class)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_val_class, y_pred_class)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "def predict(image_path):\n",
        "    image = Image.open(image_path).convert(\"L\")\n",
        "    image = np.array(image, dtype=np.float32) / 255.0\n",
        "    image = preprocess_cnv(image)\n",
        "    image = resize(image, (28, 28))\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    prediction = model.predict(image)[0]\n",
        "    return prediction\n",
        "\n",
        "def transfer_style(image_path, target_style_path, desired_size=256):\n",
        "    original_image = Image.open(image_path).convert(\"RGB\")\n",
        "    target_image = Image.open(target_style_path).convert(\"RGB\")\n",
        "    original_image = np.array(original_image, dtype=np.float32) / 255.0\n",
        "    target_image = np.array(target_image, dtype=np.float32) / 255.0\n",
        "    original_image = resize(original_image, (desired_size, desired_size))\n",
        "    target_image = resize(target_image, (desired_size, desired_size))\n",
        "    cyclegan = tf.keras.models.load_model(\"path/to/cyclegan_model.h5\")\n",
        "    transferred_image = cyclegan.predict([original_image, target_image])[0]\n",
        "    visualize_lime(original_image, transferred_image)\n",
        "    return transferred_image\n",
        "\n",
        "def visualize_lime(original_image, transferred_image):\n",
        "    explainer = lime.lime_image.LimeImageExplainer()\n",
        "    explanation = explainer.explain_instance(transferred_image, model.predict, top_labels=5)\n",
        "    heatmap, mask = explanation.get_image_and_mask(original_image, num_features=5)\n",
        "    plt.imshow(original_image)\n",
        "    plt.imshow(heatmap, alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "image_path_cnv = \"path/to/cnv_image.png\"\n",
        "prediction_cnv = predict(image_path_cnv)\n",
        "print(\"CNV Prediction:\", prediction_cnv)\n",
        "\n",
        "image_path_style = \"path/to/style_transfer_image.png\"\n",
        "target_style_path = \"path/to/style_image.png\"\n",
        "transferred_image = transfer_style(image_path_style, target_style_path)\n"
      ],
      "metadata": {
        "id": "YGtQvrv6AnHi",
        "outputId": "2191091d-f88c-4166-d38e-fe3c5c8883af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-162b7f05b739>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lime'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}